{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### word2vec 的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data as Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1 读取数据"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子总行数 : 42068\n"
     ]
    }
   ],
   "source": [
    "# 确保数据集存在\n",
    "assert \"ptb.train.txt\" in os.listdir(\"../data/ptb\")\n",
    "\n",
    "PTB_DATA_PATH = \"../data/ptb/\"\n",
    "\n",
    "with open(PTB_DATA_PATH + \"ptb.train.txt\", 'r') as f:\n",
    "    # 读取所有行\n",
    "    lines = f.readlines()\n",
    "    datasets = [line.split() for line in lines]\n",
    "\n",
    "print(\"句子总行数 : %d\" % (len(datasets)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 打印数据集\n",
    "\n",
    "对于数据集的前3个句子，打印每个句子的词数和前5个词。这个数据集中句尾符为\\<eos>，生僻词全用\\<unk>表示，数字则被替换成了\"N\"。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# token :  24 ['aer', 'banknote', 'berlitz', 'calloway', 'centrust']\n",
      "# token :  15 ['pierre', '<unk>', 'N', 'years', 'old']\n",
      "# token :  11 ['mr.', '<unk>', 'is', 'chairman', 'of']\n"
     ]
    }
   ],
   "source": [
    "for line in datasets[:3]:\n",
    "    print(\"# token : \", len(line), line[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.3 建立词语索引\n",
    "\n",
    "- 为了计算简单，我们只保留在数据集中至少出现5次的词。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "887521\n",
      "9999\n",
      "9582\n"
     ]
    }
   ],
   "source": [
    "# [word for line in datasets for word in line] 写法等价于下面的方法\n",
    "# for line in datasets:\n",
    "#     for word in line:\n",
    "#         print(word)\n",
    "\n",
    "words = [word for line in datasets for word in line]\n",
    "# {'the': 50770} => {单词:词频}\n",
    "counter = collections.Counter(words)\n",
    "print(len(words))\n",
    "print(len(counter))\n",
    "\n",
    "# 过滤掉词频小于5的单词\n",
    "counter = dict(filter(lambda x: x[1] > 5, counter.items()))\n",
    "print(len(counter))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.4 将数据集转换为索引\n",
    "\n",
    "- 上一步建立词语索引后, 我们使用词语索引将数据集中的句子中的单词转换为索引\n",
    "- 总结 :\n",
    "    1. 使用 collections.Counter 统计词频, 传入单词表, 生成  {'the': 50770} => {单词:词频} 这样的字典\n",
    "    2. 过滤掉词频过小的单词\n",
    "    3. 对单词建立索引, 使用 enumerate(word_all)\n",
    "    4. 遍历数据集, 得到每一个句子, 然后再遍历句子得到单词, 使用单词索引表将单词转换为索引, 然后存储到句子索引数组中\n",
    "    5. 然后将句子索引数组放到新数据集中, 例子如下 : 可以看到数组中有三个索引数组, 每一个数组都代表一个句子\n",
    "    6. [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],  [14, 1, 15, 16, 19, 20, 21],  [22, 1, 2, 3,10, 11, 12, 17, 31, 32, 33, 34]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pierre', '<unk>']\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 2], [14, 1, 15, 16, 17, 1, 18, 7, 19, 20, 21], [22, 1, 2, 3, 4, 23, 24, 16, 17, 25, 26, 27, 28, 29, 30, 10, 11, 12, 17, 31, 32, 33, 34]]\n",
      "885720\n"
     ]
    }
   ],
   "source": [
    "# 获取所有的单词\n",
    "word_all = [word for word, count in counter.items()]\n",
    "print(word_all[:2])\n",
    "\n",
    "# 对单词建立索引\n",
    "# {'pierre': 0, '<unk>': 1, 'N': 2, 'years': 3}\n",
    "word_to_idx = {word: index for index, word in enumerate(word_all)}\n",
    "\n",
    "# 将数据集转换为词索引\n",
    "dataset_idx = []\n",
    "# 将每一个句子中所有的单词转换为索引, 然后放到一个数组里, 然后再把这个数组放到整个数据集, 数据集以数组为单位\n",
    "for line in datasets:\n",
    "    line_idx = []\n",
    "    for word in line:\n",
    "        # 如果单词在索引表中\n",
    "        if word in word_to_idx:\n",
    "            line_idx.append(word_to_idx[word])\n",
    "    if len(line_idx) > 0:\n",
    "        dataset_idx.append(line_idx)\n",
    "print(dataset_idx[:3])\n",
    "num_words = sum([len(line) for line in dataset_idx])\n",
    "print(num_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.5 二次采样\n",
    "\n",
    "- [二次采样公式](https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter10_natural-language-processing/10.3_word2vec-pytorch?id=_10312-%e4%ba%8c%e6%ac%a1%e9%87%87%e6%a0%b7)\n",
    "1. 文本数据中一般会出现一些高频词，如英文中的\"the\"\"a\"和\"in\"。通常来说，在一个背景窗口中，一个词（如\"chip\"）和较低频词（如\"microprocessor\"）\n",
    "2. 同时出现比和较高频词（如“the”）同时出现对训练词嵌入模型更有益。\n",
    "3. 因此，训练词嵌入模型时可以对词进行二次采样 [2]。 具体来说，数据集中每个被索引词将有一定概率被丢弃"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word => 373961\n"
     ]
    }
   ],
   "source": [
    "# 定义二次采样函数\n",
    "def discard(idx):\n",
    "    # f(w) > t , t = 1e-4\n",
    "    return (1 - math.sqrt(1e-4 / (counter[word_all[idx]] / num_words))) > random.uniform(0, 1)\n",
    "\n",
    "\n",
    "# 进行二次采样, 转换成索引的数据集进行遍历, 然后根据词频决定去除哪些词\n",
    "subsampled_dataset = []\n",
    "for line in dataset_idx:\n",
    "    word_idxs = []\n",
    "    for word_idx in line:\n",
    "        if not discard(word_idx):\n",
    "            word_idxs.append(word_idx)\n",
    "    subsampled_dataset.append(word_idxs)\n",
    "\n",
    "print(\"word => %d\" % sum([len(line) for line in subsampled_dataset]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 统计某一个单词的采样率"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before 50770 \n",
      "after 2151 \n"
     ]
    }
   ],
   "source": [
    "def compare_counts(word):\n",
    "    before_count = 0\n",
    "    for line in dataset_idx:\n",
    "        before_count += line.count(word_to_idx[word])\n",
    "\n",
    "    after_count = 0\n",
    "    for line in subsampled_dataset:\n",
    "        after_count += line.count(word_to_idx[word])\n",
    "\n",
    "    print(\"before %d \" % before_count)\n",
    "    print(\"after %d \" % after_count)\n",
    "\n",
    "\n",
    "compare_counts('the')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before 45 \n",
      "after 45 \n"
     ]
    }
   ],
   "source": [
    "compare_counts('join')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.6 提取中心词和背景词\n",
    "\n",
    "我们将与中心词距离不超过背景窗口大小的词作为它的背景词。下面定义函数提取出所有中心词和它们的背景词。它每次在整数1和max_window_size（最大背景窗口）之间随机均匀采样一个整数作为背景窗口大小。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 定义提取背景词和中心词的代码\n",
    "\n",
    "def get_center_context(dataset, max_windows_size):\n",
    "    center, context = [], []\n",
    "    # 单个句子中的词汇必须大于2才能组成 中心词+背景词\n",
    "    for line in dataset:\n",
    "        if len(line) < 2:\n",
    "            continue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}